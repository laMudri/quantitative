\documentclass[submission,copyright,creativecommons]{eptcs}
\providecommand{\event}{SOS 2007} % Name of the event you are submitting to
\usepackage{breakurl}             % Not needed if you use pdflatex only.
\usepackage{underscore}           % Only needed if you use pdflatex.

\usepackage{stmaryrd}
\usepackage{mathpartir}
\usepackage{amssymb}
\usepackage{cmll}
\usepackage{xcolor}
\usepackage{paralist}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{mathtools}
\usepackage{tabularx}
\usepackage{tikz-cd}

\DeclareFontFamily{U}{cal}{}
\DeclareFontShape{U}{cal}{m}{n}{<->cmsy10}{}
\DeclareSymbolFont{rcal}{U}{cal}{m}{n}
\DeclareSymbolFontAlphabet{\mathcal}{rcal}

\usepackage{thmtools}
\declaretheorem[numberwithin=section]{theorem}
\declaretheorem[numberlike=theorem]{conjecture}
\declaretheorem[numberlike=theorem]{proposition}
\declaretheorem[numberlike=theorem]{lemma}
\declaretheorem[numberlike=theorem]{corollary}
\declaretheorem[numberlike=theorem]{example}
\declaretheorem[numberlike=theorem]{definition}

%\newtheorem{theorem}{Theorem}[section]
%\newtheorem{conjecture}[theorem]{Conjecture}
%\newcommand{\conjectureautorefname}{Conjecture}
%\newtheorem{proposition}[theorem]{Proposition}
%\newcommand{\propositionautorefname}{Proposition}
%\newtheorem{lemma}[theorem]{Lemma}
%\newcommand{\lemmaautorefname}{Lemma}
%\newtheorem{corollary}[theorem]{Corollary}
%\newcommand{\corollaryautorefname}{Corollary}
%\newtheorem{example}[theorem]{Example}
%\newcommand{\exampleautorefname}{Example}
%\newtheorem{definition}[theorem]{Definition}
%\newcommand{\definitionautorefname}{Definition}

\def\newelims{1}
\def\multnotation{1}
\input{../macros.tex}

\title{An Algebraically Structured Approach to Substructural Substitution}
\author{Robert Atkey
\institute{University of Strathclyde\\ Glasgow, United Kingdom}
\email{robert.atkey@strath.ac.uk}
\and
James Wood
\institute{University of Strathclyde\\ Glasgow, United Kingdom}
\email{james.wood.100@strath.ac.uk}
}
\def\titlerunning{An Algebraically Structured Approach to Substructural
  Substitution}
\def\authorrunning{R. Atkey \& J. Wood}
\begin{document}
\maketitle

\begin{abstract}
  We present a nice way to prove syntactic lemmas for linear type theory.
\end{abstract}

\section{Introduction}

\begin{itemize}
\item We present a generic and easily formalisable technique for
  establishing metatheoretic facts about substructural calculi.
\item FIXME: say why doing metatheory can be a bit tedious, especially
  when trying to formalise it.
\item The basic ideas:
  \begin{itemize}
  \item Annotate usages of variables with elements of a
    \emph{skew}-semiring. By choosing the right semiring, we can
    encode systems like Barber's Dual Intuitionistic Linear Logic
    (DILL) and the Pfenning-Davis S4 modal calculus. (Also, probably,
    variants of S4-modal logic as presented by G.A. Kavvos.)
  \item We extend McBride's technique of defining Kits as a generic
    notion of binding-preserving traversal of syntax so that it is
    usage-respecting. To define what it means for a traversal
    usage-respecting requires the development of elementatry linear
    algebra for skew-semi-rings.
  \item The payoff is that we can define several metatheoretic results
    in terms of the single notion of usage respecting traversal:
    including renaming and substitution.
  \end{itemize}
\end{itemize}

\section{Related Work}

\begin{itemize}
\item Licata, Shulman, and Riley \cite{LicataSR17}: \emph{A
    Fibrational Framework for Substructural and Modal Logics}
\end{itemize}

\section{Skew semirings}

A \emph{(left) skew monoid} is a structure $(\mathscr R, \subres, 1, *)$ such
that $(\mathscr R, \subres)$ forms a partial order, $*$ is monotonic with
respect to $\subres$, and the following laws hold.
\begin{mathpar}
  1x \subres x
  \and x \subres x1
  \and (xy)z \subres x(yz)
\end{mathpar}

Skew-monoidal categories are due to Szlach\'anyi \cite{skew}, and the notion
introduced here of a skew monoid is a decategorification of the notion of
skew-monoidal category.

A \emph{(left) skew semiring} is a structure $(\mathscr R, \subres, 0, +, 1, *)$
such that $(\mathscr R, \subres)$ forms a partial order, $+$ and $*$ are
monotonic with respect to $\subres$, $(\mathscr R, 0, +)$ forms a commutative
monoid, $(\mathscr R, \subres, 1, *)$ forms a skew monoid, and we have the
following distributivity laws.
\begin{mathpar}
  0z \subres 0
  \and (x + y)z \subres xz + yz
  \and 0 \subres x0
  \and xy + xz \subres x(y + z)
\end{mathpar}

\begin{example}
  TODO: some examples (are there any that are actually skew?)
\end{example}

A mnemonic for skew semirings is ``multiplication respects operators on the left
from left to right, and respects operators on the right from right to left''.
One may also describe multiplication as ``respecting'' and ``corespecting''
operators on the left and right, respectively.
Skew semirings are a generalisation of semirings, which are in turn a
generalisation of commutative semirings.
As such, readers unfamiliar with the more general structures may wish to think
in terms of the more specific structures.
In this paper, we only speak of \emph{left} skew semirings, and thus generally
omit the word ``left''.

Elements of a skew semiring are used in this paper as \emph{usage annotations},
and describe \emph{how} values are used in a program.
In the syntax for \name, each assumption will have a usage annotation,
describing how that assumption can be used in the derivation.
The additive structure describes how to combine multiple usages of an
assumption, and the multiplicative structure describes what happens when usage
requirements are composed.
In standard proof tree notation, addition can be seen as acting horizontally,
whereas multiplication acts vertically.
The ordering describes the specificness of annotations.
If $\pi \subres \rho$, $\pi$ can be the annotation for a variable wherever
$\rho$ can be.
We can read this relation as ``$\textrm{supply} \subres \textrm{demand}$'' ---
where we demand that a variable be used according to $\rho$, it is also fine to
use it as $\pi$.

\subsection{Vectors and matrices}

BOB: how much of this section could be left until after the syntax? I
feel like readers may want to see what the calculus looks like as
quickly as possible.

\begin{definition}
  A \emph{(left) semimodule} over a (left) skew semiring $\mathscr R$ is a
  structure
  $(\mathscr M, \subres,
  0 : \mathscr M, + : \mathscr M \times \mathscr M \to \mathscr M,
  * : \mathscr R \times \mathscr M \to \mathscr M)$ such that
  \begin{itemize}
    \item $+$ and $*$ are monotonic in both arguments.
    \item $(\mathscr M, 0, +)$ is a commutative monoid
    \item Scaling of a fixed element $m$ respects all of the skew semiring
      structure particularly:
      \begin{itemize}
        \item $0_\mathscr R * m \subres 0_\mathscr M$
        \item $(\pi +_\mathscr R \rho) * m \subres \pi * m +_\mathscr M \rho * m$
        \item $1_\mathscr R * m \subres m$
        \item $(\pi *_\mathscr R \rho) * m \subres \pi * (\rho * m)$
      \end{itemize}
    \item Scaling by a fixed element $\pi$ corespects the additive structure;
      particularly:
      \begin{itemize}
        \item $0_\mathscr M \subres \pi * 0_\mathscr M$
        \item $\pi * m +_\mathscr M \pi * n \subres \pi * (m +_\mathscr M n)$
      \end{itemize}
  \end{itemize}
\end{definition}

\begin{definition}
  A \emph{(left) skew semimodule homomorphism} or \emph{linear map} between
  $\mathscr R$-left semimodules $\mathscr M$ and $\mathscr N$ is a function $T$
  on the underlying sets written postfix such that all of the semimodule
  structure is respected.
  Particularly,
  \begin{itemize}
  \item $(0_\mathscr M)T \subres 0_\mathscr N$
  \item $(m +_\mathscr M n)T \subres (m)T +_\mathscr N (n)T$
  \item $(\pi *_\mathscr M m)T \subres \pi *_\mathscr N (m)T$
  \end{itemize}
\end{definition}

A skew semiring is just about enough structure to let us talk about finite
vectors, and let us represent linear maps as matrices.
To the standard operations of addition, scaling, and multiplication of vectors
and matrices, we also say that the order lifts pointwise.

Conversely to standard practice, matrices will typically right-multiply vectors,
rather than left-multiply.
Following this practice, a linear transformation
$T : \mathscr R^m \to \mathscr R^n$ is represented by an $m \times n$ matrix
$M_T$, and the application of a linear map $(v)T$ is represented by $vM_T$.

\begin{definition}[Standard basis]
  \begin{align*}
    \langle i \rvert_j =
    \begin{cases}
      1, & \textrm{if }i = j \\
      0, & \textrm{otherwise} \\
    \end{cases}
  \end{align*}
\end{definition}

\begin{definition}[Matrix operations]
    \begin{align*}
      0 &: \mathrm{Mat}~m~n \\
      0_{ij} &= 0 \\
      + &: \mathrm{Mat}~m~n \times \mathrm{Mat}~m~n \to \mathrm{Mat}~m~n \\
      (M + N)_{ij} &= M_{ij} + N_{ij} \\
      I &: \mathrm{Mat}~m~m \\
      I_{ij} &= \langle i \rvert_j \\
      * &: \mathrm{Mat}~m~n \times \mathrm{Mat}~n~o \to \mathrm{Mat}~m~o \\
      (MN)_{ik} &= \sum_j M_{ij}N_{jk}
    \end{align*}
\end{definition}

\begin{lemma}
  Natural numbers and matrices between them form a symmetric monoidal category.
\end{lemma}

\begin{lemma}
  Each matrix $M : \mathrm{Mat}~m~n$ gives rise to a linear map
  $T_M : \mathscr R^m \to \mathscr R^n$ by right-multiplication.
\end{lemma}
\begin{proof}
  We observe the following inequalities:
  \begin{itemize}
  \item $\left(\vec 0M\right)_{k} = \sum_j 0M_{jk} \subres 0 = \vec 0_{k}$
  \item $\left((u + v)M\right)_{k} = \sum_j \left(u_j + v_j\right)M_{jk} \subres
    \sum_j u_jM_{jk} + \sum_j v_jM_{jk} = (uM + vM)_{k}$
  \item $\left((\pi u)M\right)_{k} = \sum_j \pi u_jM_{jk} \subres
    \pi\sum_j u_jM_{jk} = \left(\pi(uM)\right)_{k}$
  \end{itemize}
\end{proof}

\begin{lemma}
  Each linear map $T : \mathscr R^m \to \mathscr R^n$ gives rise to a matrix
  $M : \mathrm{Mat}~m~n$ such that for each $u$, $uT \subres uM$.
\end{lemma}
\begin{proof}
  We construct $M$ as follows.
  \[
    M_{jk} = (\langle j \rvert)T_k
  \]
  Then, consider $uT_k$.
  \[
    uT_k \subres \left(\sum_j u_j\langle j \rvert\right)T_k
    \subres \sum_j u_j\langle j \rvert T_k
    = \sum_j u_j M_{jk} = (uM)_k
  \]
\end{proof}

In what follows, matrices/linear maps will only appear to the right of a
$\subres$, so when we ask for a matrix rather than a linear map, this is no loss
of generality.

\section{Syntax}

We fixed skew semiring $\mathscr R$, of which all elements, and vectors and
matrices thereof, are coloured \rescomment{green}.

\subsection{Variables}

We find it useful to distinguish between \emph{intuitionistic} variables, which
are indices into a context with a specified type, and \emph{usage-cheked} or
\emph{linear} variables, which describe the conditions under which a variable
can be used in a context, subject to the constraints of usage annotations.
Concerning the latter, a variable may be used in a context if its annotation is
$\subres \rescomment 1$ (``usable''), and the annotation of every other variable
is $\subres \rescomment 0$ (``discardable'').

\begin{definition}[intuitionistic variable]
  We write $\Gamma \ni A$ as the type of variables in $\Gamma$ with type $A$.
\end{definition}

\begin{definition}[usage-checked variable]
  We write $\ctx{\Gamma}{R} \lvar A$ as the type of $i : \Gamma \ni A$ such that
  $\resctx R \subres \langle i \rvert$.
\end{definition}

\subsection{Terms}

Our calculus is a refinement of simply typed $\lambda$-calculus sporting usage
annotations from $\mathscr R$ on variables in the context and constraints on
term formation based on these annotations.
Type formers are mostly standard from intuitionistic linear logic --- functions,
multiplicative and additive products and their units, and additive sums and
their unit.
Additionally, we have an annotated bang ($\excl{\rho}{A}$), forming a graded
comonad (assuming definitions tweaked to account for $\subres$ and skewness).

\begin{mathpar}
  \inferrule*[right=var]
  {x : \ctx{\Gamma}{R} \lvar A}
  {x : \ctx{\Gamma}{R} \vdash A}

  \and

  \inferrule*[right=$\fun{}{}$-E]
  {M : \ctx{\Gamma}{P} \vdash \fun{A}{B}
    \\ N : \ctx{\Gamma}{Q} \vdash A
    \\ \resctx R \subres \resctx P + \resctx Q
  }
  {\app{M}{N} : \ctx{\Gamma}{R} \vdash B}
  \and
  \inferrule*[right=$\fun{}{}$-I]
  {\bind{x}M : \ctx{\Gamma}{R}, \ctxvar{x}{A}{1} \vdash B}
  {\lam{x}{\bind{x}M} : \ctx{\Gamma}{R} \vdash \fun{A}{B}}

  \and

  \inferrule*[right=$\tensorOne$-E]
  {M : \ctx{\Gamma}{P} \vdash \tensorOne{}
    \\ N : \ctx{\Gamma}{Q} \vdash C
    \\ \resctx R \subres \resctx P + \resctx Q
  }
  {\del{C}{M}{N} : \ctx{\Gamma}{R} \vdash C}
  \and
  \inferrule*[right=$\tensorOne$-I]
  {\resctx R \subres \rescomment{\vct 0}}
  {\unit{} : \ctx{\Gamma}{R} \vdash \tensorOne{}}
  \and
  \inferrule*[right=$\tensor{}{}$-E]
  {M : \ctx{\Gamma}{P} \vdash \tensor{A}{B}
    \\ \bind{x,y}N : \ctx{\Gamma}{Q}, \ctxvar{x}{A}{1}, \ctxvar{y}{B}{1} \vdash C
    \\ \resctx R \subres \resctx P + \resctx Q
  }
  {\prm{C}{M}{x}{y}{\bind{x,y}N} : \ctx{\Gamma}{R} \vdash C}
  \and
  \inferrule*[right=$\tensor{}{}$-I]
  {M : \ctx{\Gamma}{P} \vdash A
    \\ N : \ctx{\Gamma}{Q} \vdash B
    \\ \resctx R \subres \resctx P + \resctx Q
  }
  {\ten{M}{N} : \ctx{\Gamma}{R} \vdash \tensor{A}{B}}

  \and

  \inferrule*[right=$\sumTZero$-E]
  {M : \ctx{\Gamma}{P} \vdash \sumTZero{}
    \\ \resctx R \subres \resctx P + \resctx Q
  }
  {\exf{C}{M} : \ctx{\Gamma}{R} \vdash C}
  \and
  (\textrm{no }\TirName{$\sumTZero$-I})
  \and
  \inferrule*[right=$\sumT{}{}$-E]
  {M : \ctx{\Gamma}{P} \vdash \sumT{A}{B}
    \\ \bind{x}N : \ctx{\Gamma}{Q}, \ctxvar{x}{A}{1} \vdash C
    \\ \bind{y}O : \ctx{\Gamma}{Q}, \ctxvar{y}{B}{1} \vdash C
    \\ \resctx R \subres \resctx P + \resctx Q
  }
  {\cse{C}{M}{x}{\bind{x}N}{y}{\bind{y}O} : \ctx{\Gamma}{R} \vdash C}
  \and
  \inferrule*[right=$\sumT{}{}$-Il]
  {M : \ctx{\Gamma}{R} \vdash A}
  {\inj{L}{M} : \ctx{\Gamma}{R} \vdash \sumT{A}{B}}
  \and
  \inferrule*[right=$\sumT{}{}$-Ir]
  {M : \ctx{\Gamma}{R} \vdash B}
  {\inj{R}{M} : \ctx{\Gamma}{R} \vdash \sumT{A}{B}}

  \and

  (\textrm{no }\TirName{$\withTOne$-E})
  \and
  \inferrule*[right=$\withTOne$-I]
  { }
  {\eat{} : \ctx{\Gamma}{R} \vdash \withTOne}
  \and
  \inferrule*[right=$\withT{}{}$-El]
  {M : \ctx{\Gamma}{R} \vdash \withT{A}{B}}
  {\proj{L}{M} : \ctx{\Gamma}{R} \vdash A}
  \and
  \inferrule*[right=$\withT{}{}$-Er]
  {M : \ctx{\Gamma}{R} \vdash \withT{A}{B}}
  {\proj{R}{M} : \ctx{\Gamma}{R} \vdash B}
  \and
  \inferrule*[right=$\withT{}{}$-I]
  {M : \ctx{\Gamma}{R} \vdash A
    \\ N : \ctx{\Gamma}{R} \vdash B
  }
  {\wth{M}{N} : \ctx{\Gamma}{R} \vdash \withT{A}{B}}

  \and

  \inferrule*[right=$\excl{\rho}{}$-E]
  {M : \ctx{\Gamma}{P} \vdash \excl{\rho}{A}
    \\ \bind{x}N : \ctx{\Gamma}{Q}, \ctxvar{x}{A}{\rho} \vdash C
    \\ \resctx R \subres \resctx P + \resctx Q
  }
  {\bm{C}{M}{x}{\bind{x}N} : \ctx{\Gamma}{R} \vdash C}
  \and
  \inferrule*[right=$\excl{\rho}{}$-I]
  {M : \ctx{\Gamma}{P} \vdash A
    \\ \resctx R \subres \rescomment\rho\resctx P
  }
  {\bang{M} : \ctx{\Gamma}{R} \vdash \excl{\rho}{A}}
\end{mathpar}

\section{Metatheory}

We prove all of our main syntactic lemmas via McBride's kits and traversals
method \cite{rensub05}.
Our main modifications are the following.
\begin{itemize}
  \item Kits need not support arbitrary weakening, but rather weakening by the
    introduction of $\rescomment 0$-use variables.
    They must also respect $\subres$.
  \item The environment is made linear by equipping it with a matrix (linear
    map) mediating between the input and output usage annotations.
\end{itemize}

\subsection{Kit}

A kit is a structure on relations
$\kitrel : \mathrm{Ctx} \times \mathrm{Ty} \to \mathrm{Set}$, intuitively
giving a way in which $\kitrel$ lives between the usage-checked variable
judgement $\lvar$ and the typing judgement $\vdash$.
We require the following functions, where all variables signified by letters are
universally quantified.

\begin{itemize}
  \item
    $\mathit{psh} : \resctx P \subres \resctx Q \to
    \ctx{\Gamma}{Q} \kitrel A \to \ctx{\Gamma}{P} \kitrel A$
  \item $\mathit{vr} : \ctx{\Gamma}{P} \lvar A \to
    \ctx{\Gamma}{P} \kitrel A$
  \item $\mathit{tm} : \ctx{\Gamma}{P} \kitrel A \to
    \ctx{\Gamma}{P} \vdash A$
  \item $\mathit{wk} : \ctx{\Gamma}{P} \kitrel A \to
    \ctx{\Gamma}{P}, \ctx{\Delta}{\vct 0} \kitrel A$
\end{itemize}

An inhabitant of $\ctx{\Gamma}{P} \kitrel A$ is described as
\emph{stuff in $\ctx{\Gamma}{P}$ of type $A$}.

\subsection{Environment}

In simple intuitionistic type theory, an environment is just a type-preserving
function from variables in the old context $\Delta$ to stuff in the new context
$\Gamma$.
That is, the environment is an inhabitant of
$\Delta \ni A \to \Gamma \kitrel A$.
The traversal function $\mathit{trav}$ turns such an environment into a map
between terms, $\Delta \vdash A \to \Gamma \vdash A$.

In \name, we want inhabitants of
$\ctx{\Delta}{Q} \vdash A \to \ctx{\Gamma}{P} \vdash A$.
We can see that an environment of type
$\ctx{\Delta}{Q} \lvar A \to \ctx{\Gamma}{P} \kitrel A$ would
be insufficient --- $\ctx{\Delta}{Q} \lvar A$ can only be inhabited when
$\resctx Q$ is compatible with a basis vector, so our environment would be
trivial in more general cases.
Instead, we care about non-usage-checked variables $\Delta \ni A$.

Our understanding of an environment is that it should simultaneously map all of
the usage-checked variables in $\ctx{\Delta}{Q}$ to stuff in $\ctx{\Gamma}{P}$
in a way that preserves usage.
As such, we want to map each variable $j : \Delta \ni A$ not to $A$-stuff in
$\ctx{\Gamma}{P}$, but rather $A$-stuff in $\resctx P_j\Gamma$,
where $\resctx P_j$ is some fragment of $\resctx P$.
Precisely, when weighted by $\resctx Q\lvert j \rangle$, we want these
$\resctx P_j$ to sum to $\resctx P$, so as to provide ``enough'' usage to cover
all of the variables $j$.
When we collect all of the $\resctx P_j$ into a matrix $\rescomment\Psi$, we
notice that the condition just described is stated succinctly via a
vector-matrix multiplication $\resctx Q\rescomment\Psi$.

This culminates to give us the following requirements.

\begin{itemize}
  \item $\rescomment\Psi : \mathscr R^{n \times m}$
  \item $\mathit{act} :
    (j : (\Delta \ni A)) \to (\langle j \rvert\rescomment\Psi)\Gamma \kitrel A$
  \item with usage condition $\resctx P \subres \resctx Q \rescomment\Psi$.
\end{itemize}

We shall write the type of such bundles as
$\ctx{\Gamma}{P} \subst{\kitrel} \ctx{\Delta}{Q}$.

\subsection{Traversal}

We shall prove the following result in \autoref{sec:proof-of-traversal}.
We state it now so as to derive renaming and substitution as quickly as
possible.

\newcommand{\thmtrav}{%
  Given a kit on $\kitrel$ and an environment
  $\ctx{\Gamma}{P} \subst{\kitrel} \ctx{\Delta}{Q}$, we can transform a term
  $\ctx{\Delta}{Q} \vdash A$ into a term $\ctx{\Gamma}{P} \vdash A$.%
}
\begin{theorem}[traversal]\label{thm:trav}
  \thmtrav
\end{theorem}

\subsection{Renaming}

\begin{definition}\label{def:lvar-kit}
  Let $\lvar\textrm{-kit} : \kit(\lvar)$ be defined with the following
  fields.
  \begin{description}
    \item[$\mathit{psh}~(\mathit{PQ} : \resctx P \subres \resctx Q)
      : \ctx{\Gamma}{Q} \lvar A \to \ctx{\Gamma}{P} \lvar A$:]
      Notice that the only occurrence of the usage context in the definition of
      $\lvar$ is to the left of a $\subres$.
      Thus, applying transitivity in this place gets us the required term.
    \item[$\mathit{vr} : \ctx{\Gamma}{P} \lvar A \to \ctx{\Gamma}{P} \lvar A
      := \mathrm{id}$].
    \item[$\mathit{tm} : \ctx{\Gamma}{P} \lvar A \to \ctx{\Gamma}{P} \vdash A
      := \TirName{var}$].
    \item[$\mathit{wk} : \ctx{\Gamma}{P} \lvar A
      \to \ctx{\Gamma}{P}, \ctx{\Delta}{\vct 0} \lvar A$:]
      Notice that a basis vector extended by $\rescomment 0$s is still a basis
      vector.
      So, given that we have $\resctx P \subres \langle i \rvert$ for some $i$,
      we also have
      $\resctx P, \rescomment{\vct 0} \subres \langle \inl i \rvert$.
  \end{description}
\end{definition}

Environments for renamings are special in that the matrix $\rescomment\Psi$ can
be calculated from the action of the renaming on non-usage-checked variables.

\begin{lemma}\label{lem:ren-env}
  Given a type-preserving mapping of intuitionistic variables
  $f : \Delta \ni A \to \Gamma \ni A$ such that
  $\resctx P \subres \resctx Q\rescomment I_{f\times\id}$,
  we can produce a $\lvar$-environment of type
  $\ctx{\Gamma}{P} \subst{\lvar} \ctx{\Delta}{Q}$.
\end{lemma}
\begin{proof}
  The environment has $\rescomment\Psi := \rescomment I_{f\times\id}$,
  so the usage condition holds by assumption.
  Now, $\mathit{act}$ is required to have type
  $(j : \Delta \ni A) \to (\langle j \rvert\rescomment\Psi)\Gamma \lvar A$.
  Take arbitrary $j : \Delta \ni A$.
  Then, we have $f~j : \Gamma \ni A$, so all that is left is to show that $f~j$
  forms a usage-checked variable of type
  $(\langle j \rvert\rescomment\Psi)\Gamma \lvar A$.
  This amounts to proving
  $\langle j \rvert\rescomment\Psi \subres \langle f~j \rvert$.
  We prove this pointwise.
  Let $i : \Gamma \ni A$.
  Then, we have the following.
  \[\begin{eqns}
      (\langle j \rvert\rescomment\Psi)_i
      \subres & \rescomment\Psi_{j,i} \\
      = & \rescomment I_{f~j,i} \\
      = & \langle f~j \rvert_i \\
    \end{eqns}\]
\end{proof}

\begin{corollary}[renaming]\label{cor:ren}
  Given a type-preserving mapping of intuitionistic variables
  $f : \Delta \ni A \to \Gamma \ni A$ such that
  $\resctx P \subres \resctx Q\rescomment I_{f\times\id}$,
  we can produce a function of type
  $\ctx{\Delta}{Q} \vdash A \to \ctx{\Gamma}{P} \vdash A$.
\end{corollary}
\begin{proof}
  By the lemmas from this subsection and \autoref{thm:trav}.
\end{proof}

\subsection{Substitution}

\begin{definition}\label{tm-kit}
  Let $\vdash\textrm{-kit} : \kit(\vdash)$ be defined with the following
  fields.
  \begin{description}
    \item[$\mathit{psh}~(\mathit{PQ} : \resctx P \subres \resctx Q)
      : \ctx{\Gamma}{Q} \vdash A \to \ctx{\Gamma}{P} \vdash A$:]
      We can use a specialised version of \hyperref[cor:ren]{renaming} in which
      the variable mapping $f$ is the identity function.
      It remains to check that
      $\resctx P \subres \resctx Q\rescomment I_{\id\times\id}$, which is
      obvious from the assumption $\mathit{PQ}$.

      Alternatively, we can note that in every rule for
      $\ctx{\Gamma}{R} \vdash A$, $\resctx R$ only ever appears to the left of a
      $\subres$, so $\ctx{\Gamma}{R} \vdash A$ must be contravariant in
      $\resctx R$.
    \item[$\mathit{vr} : \ctx{\Gamma}{P} \lvar A \to \ctx{\Gamma}{P} \vdash A
      := \TirName{var}$].
    \item[$\mathit{tm} : \ctx{\Gamma}{P} \vdash A \to \ctx{\Gamma}{P} \vdash A
      := \mathrm{id}$].
    \item[$\mathit{wk} : \ctx{\Gamma}{P} \vdash A
      \to \ctx{\Gamma}{P}, \ctx{\Delta}{\vct 0} \vdash A$:]
      We use a standard \hyperref[cor:ren]{renaming}, with
      $f : \Gamma \ni A \to \Gamma, \Delta \ni A$ being the embedding $\inl$.
      It remains to check that
      $(\resctx P, \rescomment{\vct 0}) \subres
      \resctx P\rescomment I_{\inl\times\id}$.
      We prove this pointwise.
      Let $i : \Gamma, \Delta \ni A$, and take cases on whether $i$ is from
      $\Gamma$ or from $\Delta$.
      If $i = \inl i'$ for an $i' : \Gamma \ni A$, we must show that
      $\resctx P_{i'} \subres
      (\resctx P\rescomment I_{\inl\times\id})_{\inl i'}$.
      But we have the following.
      \[\begin{eqns}
          \resctx P_{i'} \subres & (\resctx P\rescomment I)_{i'} \\
          = & \sum_{j : \Gamma \ni A} \resctx P_j\rescomment I_{j,i'} \\
          = & \sum_{j : \Gamma \ni A} \resctx P_j\rescomment I_{\inl j,\inl i'} \\
          = & (\resctx P\rescomment I_{\inl\times\id})_{\inl i'}.
        \end{eqns}\]
      If $i = \inr i'$ for an $i' : \Delta \ni A$, we must show that
      $\rescomment 0 \subres
      (\resctx P\rescomment I_{\inl\times\id})_{\inr i'}$.
      But we have the following.
      \[\begin{eqns}
          \rescomment 0 \subres & (\resctx P\rescomment{\vct 0})_{i'} \\
          = & \sum_{j : \Gamma \ni A} \resctx P_j\rescomment{\vct 0}_{j,i'} \\
          = & \sum_{j : \Gamma \ni A} \resctx P_j\rescomment I_{\inl j,\inr i'} \\
          = & (\resctx P\rescomment I_{\inl\times\id})_{\inr i'}.
        \end{eqns}\]
  \end{description}
\end{definition}

\begin{corollary}[substitution]\label{cor:sub}
  Given an environment of type $\ctx{\Gamma}{P} \subst{\vdash} \ctx{\Delta}{Q}$,
  we get a function of type
  $\ctx{\Delta}{Q} \vdash A \to \ctx{\Gamma}{P} \vdash A$.
\end{corollary}
\begin{proof}
  By \autoref{thm:trav} using \hyperref[tm-kit]{$\vdash\textrm{-kit}$}.
\end{proof}

\subsection{Proof of traversal}
\label{sec:proof-of-traversal}

The proof of the traversal theorem follows the same structure as in McBride's
article, augmented with usage checking and more term formation rules.

\begin{lemma}[bind]\label{lem:bind}
  Given a kit on $\kitrel$, we can extend an environment of type
  $\ctx{\Gamma}{P} \subst{\kitrel} \ctx{\Delta}{Q}$, to an environment of type
  $\ctx{\Gamma}{P}, \ctx{\Theta}{R} \subst{\kitrel}
  \ctx{\Delta}{Q}, \ctx{\Theta}{R}$.
\end{lemma}
\begin{proof}
  Let the environment we are given be
  $(\rescomment\Psi : \mathscr R^{n \times m},
  \mathit{act} : (j : \Delta \ni A) \to (\langle j \rvert\rescomment\Psi)\Gamma \kitrel A)$,
  with $\resctx P \subres \resctx Q \rescomment\Psi$.
  We are trying to construct
  $(\rescomment{\Psi'} : \mathscr R^{(n + o) \times (m + o)},
  \mathit{act'} : (j : \Delta, \Theta \ni A) \to
  (\langle j \rvert\rescomment\Psi')(\Gamma, \Theta) \kitrel A)$,
  with $\resctx P, \resctx R \subres (\resctx Q, \resctx R) \rescomment\Psi'$.

  Let \(
    \rescomment\Psi' := \left(\begin{array}{c|c}
                                \rescomment\Psi & \rescomment{\mat 0}
                                \\ \hline
                                \rescomment{\mat 0} & \rescomment{\mat I}
                              \end{array}\right).
  \)
  With this definition, our required condition splits into the following easily
  checked conditions.
  \begin{itemize}
    \item
      $\resctx P \subres
      \resctx Q\rescomment\Psi + \resctx R\rescomment{\mat 0}$
    \item
      $\resctx R \subres
      \resctx Q\rescomment{\mat 0} + \resctx R\rescomment{\mat I}$
  \end{itemize}

  For $\mathit{act'}$, we take cases on whether $j$ is from $\Delta$ or from
  $\Theta$.

  In the $\Delta$ case, $\mathit{act}$ gets us an inhabitant of
  $(\langle j \rvert\rescomment\Psi)\Gamma \kitrel A$.
  Notice that
  $\langle j \rvert\rescomment\Psi' =
  \langle j \rvert\rescomment\Psi, \rescomment{\vct 0}$,
  so we want to get from $(\langle j \rvert\rescomment\Psi)\Gamma \kitrel A$ to
  $(\langle j \rvert\rescomment\Psi)\Gamma, \rescomment{\vct 0}\Theta
  \kitrel A$.
  We can get this using $\mathit{wk}$ from our kit.

  In the $\Theta$ case, notice that
  $\langle j \rvert\rescomment\Psi' = \rescomment{\vct 0}, \langle j \rvert$.
  In other words, $\langle j \rvert\rescomment\Psi'$ is a basis vector, so we
  actually have usage-checked
  $(\langle j \rvert\rescomment\Psi')(\Gamma, \Theta) \lvar A$.
  Thus, we can use $\mathit{vr}$ from our kit to get
  $(\langle j \rvert\rescomment\Psi')(\Gamma, \Theta) \kitrel A$, as required.
\end{proof}

\newtheorem*{thm:trav}{\autoref{thm:trav}}
\begin{thm:trav}[traversal]
  \thmtrav
\end{thm:trav}
\begin{proof}
  By induction on the syntax of $M$.
  We give a selection of representitive cases first.
  Non-\TirName{var} cases are all some combination of the following parts.
  \begin{itemize}
    \item If the input usage context $\resctx Q$ is split up into a linear
      combination of zero or more usage contexts $\resctx Q_{i}$, obtain a
      similar splitting of $\resctx P$ by setting
      $\resctx P_{i} := \resctx Q_{i}\rescomment\Psi$.
      This works out because of the linearity of matrix multiplication (in
      particular, multiplication respects operations on the left).
    \item If there are subterms, make sure that the above splitting gives rise
      to new environments of type
      $\resctx P_{i}\Gamma \subst{\kitrel} \resctx Q_{i}\Delta$.
    \item If any subterms bind variables, apply \autoref{lem:bind} as
      appropriate.
  \end{itemize}
  \begin{description}
    \item[\TirName{var} $x$, where $x : \ctx{\Delta}{Q} \lvar A$:]
      By definition of $\lvar$, we have that
      $\resctx Q \subres \langle j \rvert$ for some $j$.
      Applying the action of the environment, we have
      $(\langle j \rvert\rescomment\Psi)\Gamma \kitrel A$.
      We then have
      $\resctx P \subres \resctx Q\rescomment\Psi
      \subres \langle j \rvert\rescomment\Psi$,
      so using the fact that stuff appropriately respects subusaging
      ($\mathit{psh}$), we have $\ctx{\Gamma}{P} \kitrel A$.
      Finally, using $\mathit{tm}$, we get a term $\ctx{\Gamma}{P} \vdash A$, as
      required.
    \item[\TirName{$\withTOne$-I} $\eat$]
      We want to produce a term $\ctx{\Gamma}{P} \vdash \withTOne$, which is
      trivial with the rule \TirName{$\withTOne$-I}.
    \item[\TirName{$\withT{}{}$-I} $\wth{M}{N}$, where
      $M : \ctx{\Delta}{Q} \vdash A$, $N : \ctx{\Delta}{Q} \vdash B$:]
      Inductively, we get $M' : \ctx{\Gamma}{P} \vdash A$ and
      $N' : \ctx{\Gamma}{P} \vdash B$ from
      $M$ and $N$, respectively.
      We can combine $M'$ and $N'$ with \TirName{$\withT{}{}$-I} to get
      $\wth{M'}{N'} : \ctx{\Gamma}{P} \vdash \withT{A}{B}$, as required.
    \item[\TirName{$\withT{}{}$-El}, \TirName{$\withT{}{}$-Er},
      \TirName{$\sumT{}{}$-Il}, \TirName{$\sumT{}{}$-Ir}:]
      These all follow simply like the last two cases.
    \item[\TirName{$\tensorOne$-I} $\unit$, where
      $\resctx Q \subres \rescomment{\vct 0}$:]
      We want to use \TirName{$\tensorOne$-I} to conclude
      $\unit : \ctx{\Gamma}{P}$.
      To do this, we must show that $\resctx P \subres \rescomment{\vct 0}$.
      From the environment, we know that
      $\resctx P \subres \resctx Q\rescomment\Psi$.
      But because $\resctx Q \subres \rescomment{\vct 0}$, we get
      $\resctx P \subres \rescomment{\vct 0}\rescomment\Psi
      \subres \rescomment{\vct 0}$, as required.
    \item[\TirName{$\tensor{}{}$-I} $\ten{M}{N}$, where
      $M : \ctx{\Delta}{Q_{\mathnormal M}} \vdash A$,
      $N : \ctx{\Delta}{Q_{\mathnormal N}} \vdash B$,
      $\resctx Q \subres \resctx Q_{\rescomment M} + \resctx Q_{\rescomment N}$:]
      We want to inductively traverse $M$ and $N$.
      This will produce terms
      $M' : \ctx{\Gamma}{P_{\mathnormal M}} \vdash A$ and
      $N' : \ctx{\Gamma}{P_{\mathnormal N}} \vdash B$, for some choice of
      $\resctx P_{\rescomment M}$ and $\resctx P_{\rescomment N}$.
      Furthermore, we want
      $\resctx P \subres \resctx P_{\rescomment M} + P_{\rescomment N}$, so that
      we can combine $M'$ and $N'$ using \TirName{$\tensor{}{}$-I}, getting
      $\ten{M'}{N'} : \ctx{\Gamma}{P} \vdash \tensor{A}{B}$, as required.

      Let
      $\resctx P_{\rescomment M} := \resctx Q_{\rescomment M}\rescomment\Psi$
      and
      $\resctx P_{\rescomment N} := \resctx Q_{\rescomment N}\rescomment\Psi$,
      where $\Psi$ comes from the environment.
      We must make environments of types
      $\ctx{\Gamma}{P_{\mathnormal M}}
      \subst{\kitrel} \ctx{\Delta}{Q_{\mathnormal M}}$
      and
      $\ctx{\Gamma}{P_{\mathnormal N}}
      \subst{\kitrel} \ctx{\Delta}{Q_{\mathnormal N}}$.
      Notice that the data in these can be carried over from the environment we
      were given, but we must recheck the usage condition in each case.
      However, both of these just come down to the reflexivity of $\subres$.

      Finally, in order to apply \TirName{$\tensor{}{}$-I}, we must check that
      $\resctx P \subres \resctx P_{\rescomment M} + \resctx P_{\rescomment N}$.
      This follows by:
      \[\begin{eqns}
        \resctx P \subres & \resctx Q\rescomment\Psi \\
        \subres & (\resctx Q_{\rescomment M} + \resctx Q_{\rescomment N})
        \rescomment\Psi \\
        \subres & \resctx Q_{\rescomment M}\rescomment\Psi +
        \resctx Q_{\rescomment N}\rescomment\Psi \\
        = & \resctx P_{\rescomment M} + \resctx P_{\rescomment N}
      \end{eqns}\]
    \item[\TirName{$\fun{}{}$-E}, \TirName{$\tensorOne{}$-E},
      \TirName{$\sumTZero$-E}:]
      These all follow similarly to the above case (ignoring the lack of a
      subterm $N$ in the \TirName{$\sumTZero$-E} case).
    \item[\TirName{$\excl{\rho}{}$-I} $\bang{M}$, where
      $M : \ctx{\Delta}{Q_{\mathnormal M}} \vdash A$,
      $\resctx Q \subres \resctx \rho Q_{\rescomment M}$:]
      Following a similar strategy to the case above, let
      $\resctx P_{\rescomment M} := \resctx Q_{\rescomment M}\rescomment\Psi$.
      If we get a term $M' : \ctx{\Gamma}{P_{\mathnormal M}} \vdash A$, we will
      be able to apply \TirName{$\excl{\rho}{}$-I} to get the result because
      \[\begin{eqns}
          \resctx P_{\rescomment M} = & \resctx Q_{\rescomment M}\rescomment\Psi \\
          \subres & (\rho\resctx Q)\rescomment\Psi \\
          \subres & \rho(\resctx Q\rescomment\Psi) \\
          \subres & \rho\resctx P.
        \end{eqns}\]

      To get $M'$, we traverse $M$ with the same environment at type
      $\ctx{\Gamma}{P_{\mathnormal M}}
      \subst{\kitrel} \ctx{\Delta}{Q_{\mathnormal M}}$.
      The usage condition reduces to the definition of
      $\resctx P_{\rescomment M}$.
    \item[\TirName{$\fun{}{}$-I} $\lam{x}{M}$, where
      $M : \ctx{\Delta}{Q}, \ctxvar{x}{A}{1} \vdash B$:]
      We want to inductively traverse $M$, yielding a term
      $M' : \ctx{\Gamma}{P}, \ctxvar{x}{A}{1}$, to which we apply
      \TirName{$\fun{}{}$-I} to get the desired result.
      The environment we use to traverse $M$ is the result of the
      \hyperref[lem:bind]{bind lemma} applied to the environment we were given.
    \item[\TirName{$\sumT{}{}$-E}, where
      $M : \ctx{\Delta}{Q_{\mathnormal M}} \vdash \sumT{A}{B}$,
      $N : \ctx{\Delta}{Q_{\mathnormal N}}, \ctxvar{x}{A}{1} \vdash C$,
      $O : \ctx{\Delta}{Q_{\mathnormal N}}, \ctxvar{y}{B}{1} \vdash C$:]
      This is the most complex rule, combining splitting, sharing, and binding.
      \ldots
    \item[\TirName{$\tensor{}{}$-E}, \TirName{$\excl{\rho}{}$-E}:]
      These both feature a similar combination of splitting and binding to the
      previous case.
      The \TirName{$\excl{\rho}{}$-E} rule involves binding a variable with
      arbitrary annotation $\rescomment\rho$, but notice that the
      \hyperref[lem:bind]{bind lemma} handles this perfectly well.
  \end{description}
\end{proof}

\section{Conclusion}

\section{Bibliography}

\bibliographystyle{eptcsalpha}
\bibliography{../quantitative}
\end{document}
