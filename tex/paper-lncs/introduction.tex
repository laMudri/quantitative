When verifying functional programs in a dependently typed programming language,
we often end up writing a program twice --- once to implement the program we
want to run, and once to prove a simple property of the program.
A standard example of this is proving that a sorting function is a permutation.
Below we have the $\textrm{sort}$ function, defined idiomatically by iteration,
and a conventional proof $\textrm{sort-perm}$ showing that it is a permutation.
We assume an $\textrm{insert}$ function, and proof $\textrm{insert-perm} :
\forall x,\mathit{xs}.~\textrm{insert}~x~xs \simeq x :: xs$.

\[
  \begin{array}{ll}
    \begin{array}[t]{l}
      \textrm{sort} : \textrm{List}~A \to \textrm{List}~A \\
      \textrm{sort} = \textrm{foldr}~[]~\textrm{insert}
    \end{array}
    \quad & \quad
      \begin{array}[t]{l}
        \textrm{sort-perm} : \forall\mathit{xs}.~\textrm{sort}~\mathit{xs} \simeq \mathit{xs} \\
        \textrm{sort-perm}~[] = [] \\
        \textrm{sort-perm}~(x :: \mathit{xs}) = \\
        \quad \textrm{insert-perm}~x~(\textrm{sort}~\mathit{xs}) \\
        \quad {}\bullet (x :: \textrm{sort-perm}~\mathit{xs})
      \end{array}
  \end{array}
\]

This proof is slightly tricky, but it is proving something obvious.
The $\textrm{insert}$ function never drops or duplicates its inputs into the
output, so it is obviously a permutation, and $\textrm{sort}$ is only made up of
functions that do no dropping or duplicating, so is also a permutation.
The aim of this paper is to make observations like this formal.

\fixme{Old stuff} In normal typed $\lambda$-calculi, variables may be used multiple
times, in multiple contexts, for multiple reasons, as long as the
types agree. The disciplines of linear types \cite{girard87linear} and
coeffects \cite{PetricekOM14,BrunelGMZ14,GhicaS14} refine this by
tracking variable usage. We might track how many times a variable is
used, or if it is used co-, contra-, or invariantly. Such a discipline
yields a general framework of ``context constrained computing'', where
constraints on variables in the context tell us something interesting
about the computation being performed.
% Thus we put the
% type information to work to tell us facts about programs that might
% not otherwise be apparent.

We will present work in progress on capturing the ``intensional''
properties of programs via a family of Kripke indexed relational
semantics that refines a simple set-theoretic semantics of
programs. The value of our approach lies in its generality. We can
accommodate the following examples:
\begin{enumerate}
\item Linear types that capture properties like ``all list
  manipulating programs are permutations''. This example uses the
  Kripke-indexing to track the collection of datums currently being
  manipulated by the program.
\item Monotonicity coeffects that track whether a program uses inputs
  co-, contra-, or in-variantly (or not at all).
\item Sensitivity typing, tracking the sensitivity of programs in
  terms of input changes. This forms the core of systems for
  differential privacy \cite{reed10distance}.
\item Information flow typing, in the style of the Dependency Core
  Calculus \cite{abadi99core}.
\end{enumerate}

The syntax and semantics we present here have been formalised in Agda:
\url{https://github.com/laMudri/quantitative/}.

Our main contributions are:

\begin{itemize}
\item A rigorous statement of substitution for a substructural type system
\item A Kripke-indexed relational semantics providing strong free theorems
\item A formalisation of this work in Agda
\end{itemize}

\subsection{Related work}

We follow closely and extend the approaches of Petricek, Orchard, and Mycroft,
and Ghica and Smith \cite{PetricekOM14,GhicaS14}.
In particular, our framework is generic in a partially ordered semiring of
\emph{usage constraints}, which are placed on each variable in the context.
This is distinct from the approach taken by Brunel et al and the Granule project
\cite{BrunelGMZ14,Granule18}, where \emph{unannotated} variables also exist, and
are treated linearly.
Both of the latter systems contain a \emph{dereliction} rule, stating that a
variable annotated $\rescomment 1$ can be coerced to an unannotated variable.
This rule can be justified by the graded comonad unit law
$\fun{\excl{1}{A}}{A}$, so adds no new axioms to be met when we want to produce
semantics.
However, the distinction between annotated and unannotated variables does cause
complexity in the syntax.
For one thing, the dereliction rule is not syntax-directed.
For another, the operation of merging contexts is now partial, and the scaling
operation is not uniform or also partial.

Beyond previous work that assumed all variables were annotated, we allow a full
complement of propositional intuitionistic linear logic connectives.
Particularly, we have tensor products, with products, sums, and the bang
modality, as opposed to just functions.
In contrast to this previous work, our functions are not annotated with a usage
constraint; we prefer a combination of the function arrow and the bang modality
so as to improve modularity of the connectives.

Our main novel language feature compared to previous work on usage-constrained
typing is an account of an inductive type (tensor lists) in both syntax and
semantics.
We believe that this account could be generalised to cover all strictly positive
inductive types in a relatively straightforward manner.