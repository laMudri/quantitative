In this section, we present a simply typed calculus that is parametric in a set
$\mathscr{R}$ of resources, under conditions detailed later in the section.

\subsection{Types}

Our grammar of types and contexts is given in \autoref{fig:syntax}.
Throughout this section, the colour \fixme{choose} highlights resource annotations, which
are generally the interesting things to watch in typing rules and the main point
of departure between this system and a standard simply typed $\lambda$-calculus.

\begin{figure}
  \begin{mathpar}
    \rescomment \rho, \rescomment \pi \in \mathscr R \and
    A, B, C \Coloneqq \fun{A}{B} \mid \tensorOne \mid \tensor{A}{B} \mid
    \withTOne \mid \withT{A}{B} \mid \sumTZero \mid \sumT{A}{B} \mid
    \excl{\rho}{A} \\
    \Gamma, \Delta \Coloneqq \cdot \mid \Gamma, x : A \and
    \resctx P, \resctx Q, \resctx R \Coloneqq
    \cdot \mid \resctx R, x^{\rescomment \rho} \and
    \ctx{\Gamma}{R} \Coloneqq
    \cdot \mid \ctx{\Gamma}{R}, \ctxvar{x}{A}{\rho}
  \end{mathpar}
  \caption{Basic syntax}
  \label{fig:syntax}
\end{figure}

We have functions, two kinds of finite products, finite sums, and a graded
modality $\excl{\rho}{}$.
These will be explained further when their typing rules are introduced.

Our contexts are combinations of a typing context $\Gamma$ and a resourcing
context $\resctx R$, written $\ctx{\Gamma}{R}$.
It will sometimes be useful to talk only about one part at a time.
In particular, it is occasionally useful to think of resourcing contexts as row
vectors, and to use standard linear algebra operations on them.

\subsection{Resource annotations}

We assume a partially ordered semiring $(\mathscr{R}, \subres, 0, +, 1, *)$ of
resource annotations.
These will adorn free variables.
$0$ represents non-usage, and $+$ the combination of separate usages.
$(\mathscr{R}, 0, +)$ forms a commutative monoid.
$1$ represents a single or plain usage, and $*$ applies a transformation upon
the type of usage allowed.
$(\mathscr{R}, 1, *)$ forms a monoid that is annihilated by and distributes over
the additive structure.
The order $\subres$ describes a sub-resourcing relation.
We have $\pi \subres \rho$ if and only if the annotation $\pi$ allows use in at
most as many situations as the annotation $\rho$ allows.
This acts a lot like a subtyping relation.
$(\mathscr{R}, \subres)$ forms a partial order, and addition and multiplication
are monotonic with respect to $\subres$.

In many cases of interest, $0$ and $+$ are respectively the bottom and join of
the sub-resourcing order, turning it into a join semilattice.
In these cases, with products ($\withT{A}{B}$) coincide with tensor products
($\tensor{A}{B}$), and resource inference is significantly simplified.
(rntz reference?)

\begin{example}[Trivial]
  The one-element partially ordered semiring provides no usage restrictions.
  The calculus becomes equivalent to a simply typed $\lambda$-calculus.
\end{example}

\begin{example}[Linearity]
  We approximate counting usages.
  $0$ and $1$ represent exactly their respective number of usages.
  $\omega$ represents unrestricted usage.
  The effect of the bang ($\oc$) modality of linear logic is achieved by
  multiplication by $\omega$, which makes everything available become
  unrestricted.

  \begin{center}
    \begin{tabular}{>{$}c<{$}}
      0 \coloneqq 0 \\
      1 \coloneqq 1
    \end{tabular}%
    \hspace{0.5in}%
    \begin{tabular}{>{$}r<{$}|>{$}l<{$}>{$}l<{$}>{$}l<{$}}
      +      & 0      & 1      & \omega \\
      \hline
      0      & 0      & 1      & \omega \\
      1      & 1      & \omega & \omega \\
      \omega & \omega & \omega & \omega \\
    \end{tabular}%
    \hspace{0.5in}%
    \begin{tabular}{>{$}r<{$}|>{$}l<{$}>{$}l<{$}>{$}l<{$}}
      *      & 0      & 1      & \omega \\
      \hline
      0      & 0      & 0      & 0      \\
      1      & 0      & 1      & \omega \\
      \omega & 0      & \omega & \omega \\
    \end{tabular}%
    \hspace{0.5in}%
    \(
    \begin{tikzcd}[arrows=dash,row sep=0.5cm,column sep=0.5cm]
      & \omega & \\
      0 \arrow[ur] && 1 \arrow[ul]
    \end{tikzcd}
    \)
  \end{center}
\end{example}

\begin{example}[Monotonicity]
  Resource annotations track which ``way up'' we can use a free variable.
  A variable can be used covariantly ($\uparrow$), contravariantly
  ($\downarrow$), invariantly ($=$), or unrestrictedly ($?$).

  \begin{center}
    \begin{tabular}{>{$}c<{$}}
      0 \coloneqq {=} \\
      1 \coloneqq {\uparrow}
    \end{tabular}%
    \hspace{0.5in}%
    \begin{tabular}{>{$}r<{$}|>{$}l<{$}>{$}l<{$}>{$}l<{$}>{$}l<{$}}
      +          & =          & \uparrow & \downarrow & ? \\
      \hline
      =          & =          & \uparrow & \downarrow & ? \\
      \uparrow   & \uparrow   & \uparrow & ?          & ? \\
      \downarrow & \downarrow & ?        & \downarrow & ? \\
      ?          & ?          & ?        & ?          & ? \\
    \end{tabular}%
    \hspace{0.5in}%
    \begin{tabular}{>{$}r<{$}|>{$}l<{$}>{$}l<{$}>{$}l<{$}>{$}l<{$}}
      *          & = & \uparrow   & \downarrow & ? \\
      \hline
      =          & = & =          & =          & = \\
      \uparrow   & = & \uparrow   & \downarrow & ? \\
      \downarrow & = & \downarrow & \uparrow   & ? \\
      ?          & = & ?          & ?          & ? \\
    \end{tabular}%
    \hspace{0.5in}%
    \(
    \begin{tikzcd}[arrows=dash,row sep=0.5cm,column sep=0.5cm]
      & ? & \\
      \uparrow \arrow[ur] && \downarrow \arrow[ul] \\
      & = \arrow[ul]\arrow[ur] &
    \end{tikzcd}
    \)
  \end{center}

  Notice that $+$ is the join of the sub-resourcing order.
\end{example}

\subsection{Typing \& resourcing}

We take typing contexts $\Gamma, \Delta$ to be vectors of types, and resourcing
contexts $\resctx P, \resctx Q, \resctx R$ to be vectors of resource
annotations.
Informally, we will index both of these by named variables $x, y, z$.
Notation of the form $\Gamma^{\resctx R}$ represents the combination of a
typing context $\Gamma$ and a resourcing context $\resctx R$ over the same set
of variables.

Typing judgements are of the form
$\ctxvar{x_1}{A_1}{\rho_1}, \ldots, \ctxvar{x_n}{A_n}{\rho_n} \vdash M : A$.
Each variable in the context carries a resource annotation, but the conclusion
is taken to always have annotation $1$.
Such a restriction is important to keep substitution admissible, as shown in
\cite{quantitative-type-theory}.

Let $\basis x$ be the $x$th basis vector $\vec 0, x^1, \vec 0$ --- that is, the
resource context in which every variable is annotated with $0$ except for $x$,
which is annotated with $1$.
Such a context describes the restriction that semantically all variables except
$x$ are unused, while $x$ is used plainly.
This makes it the principle resourcing of the variable rule.

\[
\inferrule*[right=var]
{(x : B) \in \Gamma
  \\ \subrctx{\basis x}{\resctx R}
}
{\ctx{\Gamma}{R} \vdash x : B}
\]

Allowing $\basis x \subres \resctx R$, rather than $\basis x = \resctx R$,
allows less restrictive resourcings.
For example, we are free to use $x$ if its use is unrestricted, and similarly we
are free to discard any variables with unrestricted use.

The following are the rules for $\lambda$-abstractions and application.
$\multimap$-I is standard, except for the restriction that we use the bound
variable plainly.
In $\multimap$-E, the condition $\resctx P + \resctx Q \subres \resctx R$
means that we must be able to distribute the resources of $\resctx R$ into
those used to produce the function ($\resctx P$) and those used to produce the
argument ($\resctx Q$).
Sub-resourcing is allowed here \fixme{why?}

\begin{mathpar}
  \inferrule*[right=$\multimap$-I]
  {\ctx{\Gamma}{R}, \ctxvar{x}{A}{1} \vdash M : B}
  {\ctx{\Gamma}{R} \vdash \lam{x}{M} : \fun{A}{B}}
  \and
  \inferrule*[right=$\multimap$-E]
  {\ctx{\Gamma}{P} \vdash M : \fun{A}{B}
    \\ \ctx{\Gamma}{Q} \vdash N : A
    \\ \subrctx{\resctx P + \resctx Q}{\resctx R}
  }
  {\ctx{\Gamma}{R} \vdash \app{M}{N} : B}
\end{mathpar}

In general, we distinguish between tensor products ($\otimes$) and with products
($\&$).

\fixme{Maybe as a lemma after sub-resourcing has been clearly stated
  $\rightarrow$}
As mentioned above, the distinction collapses in the case where addition is the
join of the sub-resourcing order.
This fact can be seen clearly in the introduction rules, where the condition
$\resctx P + \resctx Q \subres \resctx R$ is equivalent to the conjunction of
$\resctx P \subres \resctx R$ and $\resctx Q \subres \resctx R$.
With these and the admissibility of sub-resourcing, we get the equivalence.

\begin{mathpar}
  \inferrule*[right=$\otimes$-I]
  {\ctx{\Gamma}{P} \vdash M : A
    \\ \ctx{\Gamma}{Q} \vdash N : B
    \\ \subrctx{\resctx P + \resctx Q}{\resctx R}
  }
  {\ctx{\Gamma}{R} \vdash \ten{M}{N} : \tensor{A}{B}}
  \and
  \inferrule*[right=$\otimes$-E]
  {\ctx{\Gamma}{P} \vdash M : \tensor{A}{B}
    \\ \ctx{\Gamma}{Q}, \ctxvar{x}{A}{1}, \ctxvar{y}{B}{1} \vdash N : C
    \\ \subrctx{\resctx P + \resctx Q}{\resctx R}
  }
  {\ctx{\Gamma}{R} \vdash \prm{C}{M}{x}{y}{N} : C}

  \and

  \inferrule*[right=$\&$-I]
  {\ctx{\Gamma}{R} \vdash M : A
    \\ \ctx{\Gamma}{R} \vdash N : B
  }
  {\ctx{\Gamma}{R} \vdash \wth{M}{N} : \withT{A}{B}}
  \and
  \inferrule*[right=$\&$-E$_i$]
  {\ctx{\Gamma}{R} \vdash M : \withT{A_0}{A_1}}
  {\ctx{\Gamma}{R} \vdash \proj{i}{M} : A_i}
\end{mathpar}

A similar distinction between two types of product can be seen in various
existing systems. \fixme{refs here}

\begin{tabular}{c|c|c}
  & $\tensorOne$, $\tensor{A}{B}$ & $\withTOne$, $\withT{A}{B}$ \\ \hline
  name & tensor & with \\ \hline
  Linear logic & multiplicative conjunction & additive conjunction \\
  Type theory & eliminated by pattern matching & eliminated by projections \\
  Call-by-push-value & value & computation \\
  Monoidal category theory & monoidal product & cartesian product
\end{tabular}

To derive the units for each of the products, we turn what was then binary into
what is now nullary.

\begin{mathpar}
  \inferrule*[right=$1$-I]
  {\subrctx{\vec 0}{\resctx R}}
  {\ctx{\Gamma}{R} \vdash \unit : \tensorOne}
  \and
  \inferrule*[right=$1$-E]
  {\ctx{\Gamma}{P} \vdash M : \tensorOne
    \\ \ctx{\Gamma}{Q} \vdash N : A
    \\ \subrctx{\resctx P + \resctx Q}{\resctx R}
  }
  {\ctx{\Gamma}{R} \vdash \del{A}{M}{N} : A}

  \and

  \inferrule*[right=$\top$-I]
  { }
  {\ctx{\Gamma}{R} \vdash \eat : \withTOne}
  \and
  \text{(no $\top$-E)}
\end{mathpar}

Sums are dual to with products.
The behaviour of sums is familiar from intuitionistic type theory, except for
the splitting of resources in the elimination rules between the term being
eliminated and the continuation terms.
Notice that this splitting also happens for $0$-E ($\exf{}{}$), even though the
resourcing context $\resctx Q$ is not used in any premises.
The addition of the extra $\resctx Q$ can be seen as saying that when we are in
an impossible case (having created an expression of type $\sumTZero$), we can
ignore the restrictions imposed by the presence of remaining free variables.

\begin{mathpar}
  \text{(no $0$-I)}
  \and
  \inferrule*[right=$0$-E$_i$]
  {\ctx{\Gamma}{P} \vdash M : \sumTZero
    \\ \subrctx{\resctx P + \resctx Q}{\resctx R}
  }
  {\ctx{\Gamma}{R} \vdash \exf{A}{M} : A}

  \inferrule*[right=$\oplus$-I]
  {\ctx{\Gamma}{R} \vdash M : A_i}
  {\ctx{\Gamma}{R} \vdash \inj{i}{M} : \sumT{A_0}{A_1}}
  \and
  \inferrule*[right=$\oplus$-E]
  {\ctx{\Gamma}{P} \vdash M : \sumT{A}{B}
    \\ \ctx{\Gamma}{Q}, \ctxvar{x}{A}{1} \vdash N_0 : C
    \\ \ctx{\Gamma}{Q}, \ctxvar{y}{B}{1} \vdash N_1 : C
    \\ \subrctx{\resctx P + \resctx Q}{\resctx R}
  }
  {\ctx{\Gamma}{R} \vdash \cse{C}{M}{x}{N_0}{y}{N_1} : C}
\end{mathpar}

Bang

\begin{mathpar}
  \inferrule*[right=$\excl{\rho}{}$-I]
  {\ctx{\Gamma}{P} \vdash M : A
    \\ \subrctx{{\rho} * \resctx P}{\resctx R}
  }
  {\ctx{\Gamma}{R} \vdash \bang{M} : \excl{\rho}{A}}
  \and
  \inferrule*[right=$\excl{\rho}{}$-E]
  {\ctx{\Gamma}{P} \vdash M : \excl{\rho}{A}
    \\ \ctx{\Gamma}{Q}, \ctxvar{x}{A}{\rho} \vdash N : B
    \\ \subrctx{\resctx P + \resctx Q}{\resctx R}
  }
  {\ctx{\Gamma}{R} \vdash \bm{B}{M}{x}{N} : B}
\end{mathpar}

\fixme{Constants}

\subsection{Example programs}

\subsubsection{Monoidality}
We can show that $\excl{\rho}{}$ preserves tensor products in one direction:
$\fun{\tensor{\excl{\rho}{C}}{\excl{\rho}{D}}}{\excl{\rho}{(\tensor{C}{D})}}$.

\[
  \begin{aligned}
    \lam{bcbd}{& \prm{ }{bcbd}{bc}{bd}{\\
        & \bm{ }{bc}{c}{\\
          & \bm{ }{bd}{d}{\\
            & \bang{\ten{c}{d}}}}}}
  \end{aligned}
\]

In the resourcing derivation, the interesting part is after all of the pattern
matching has been done and we are ready to start building the result.

\[
  \inferrule*[right=$\excl{\rho}{}$-I]{
    \rho * bcbd^0, bc^0, bd^0, c^1, d^1
    \subres bcbd^0, bc^0, bd^0, c^\rho, d^\rho
    \\
    \ctxvar{bcbd}{\tensor{\excl{\rho}{C}}{\excl{\rho}{D}}}{0},
    \ctxvar{bc}{\excl{\rho}{C}}{0}, \ctxvar{bd}{\excl{\rho}{D}}{0},
    \ctxvar{c}{C}{1}, \ctxvar{d}{D}{1}
    \vdash \ten{c}{d} : \tensor{C}{D}
  }
  {
    \ctxvar{bcbd}{\tensor{\excl{\rho}{C}}{\excl{\rho}{D}}}{0},
    \ctxvar{bc}{\excl{\rho}{C}}{0}, \ctxvar{bd}{\excl{\rho}{D}}{0},
    \ctxvar{c}{C}{\rho}, \ctxvar{d}{D}{\rho}
    \vdash \bang{\ten{c}{d}} : \excl{\rho}{(\tensor{C}{D})}
  }
\]

After this move, $c$ and $d$ become amenable to the var rule, which only applies
to super-resources of $1$.

The converse cannot be implemented in general because we get to a stage where we
are essentially trying to prove $\ctxvar{cd}{\tensor{C}{D}}{\rho} \vdash
\wn : \tensor{\excl{\rho}{C}}{\excl{\rho}{D}}$.
At this point, we cannot use the variable $cd$ because we might not have
$1 \subres \rho$, and so the condition of the var rule fails.
We can do $\otimes$-I, but there is no satisfactory way to split $cd^\rho$
between the two halves.
The interpretation of this non-derivability in linear logic is that
$\excl{\omega}{(\tensor{C}{D})}$ promises an unlimited supply of $C$s and $D$s
\emph{in lock step}, whereas $\tensor{\excl{\omega}{C}}{\excl{\omega}{C}}$
promises both an unlimited supply of $C$s and an unlimited supply of $D$s with
no relation between each other.

\subsubsection{Comonad operations}
We have the following two derivations.

\begin{mathpar}
  \inferrule*[Right=$\multimap$-I]{
    \inferrule*[Right=$\excl{1}{}$-E]{
      \inferrule*[right=var]{ }
      {\ctxvar{ba}{\excl{1}{A}}{1} \vdash ba : \excl{1}{A}}
      \\
      \inferrule*[Right=var]{ }
      {\ctxvar{ba}{\excl{1}{A}}{0}, \ctxvar{a}{A}{1} \vdash a : A}
    }
    {\ctxvar{ba}{\excl{1}{A}}{1} \vdash \bm{A}{ba}{a}{a} : A}
  }
  {\vdash \lam{ba}{\bm{A}{ba}{a}{a}} : \fun{\excl{1}{A}}{A}}

  \and

  \inferrule*[Right=$\multimap$-I]{
    \inferrule*[Right=$\excl{\pi * \rho}{}$-E]{
      \inferrule*[right=var]{ }
      {\ctxvar{ba}{\excl{\pi * \rho}{A}}{1} \vdash ba : \excl{\pi * \rho}}
      \\
      \inferrule*[Right=$\excl{\pi}{}$-I]{
        \inferrule*[Right=$\excl{\rho}{}$-I]{
          \inferrule*[Right=var]{ }
          {\ctxvar{ba}{\excl{\pi * \rho}{A}}{0}, \ctxvar{a}{A}{1} \vdash
            a : A}
        }
        {\ctxvar{ba}{\excl{\pi * \rho}{A}}{0}, \ctxvar{a}{A}{\rho} \vdash
          \bang{a} : \excl{\rho}{A}}
      }
      {\ctxvar{ba}{\excl{\pi * \rho}{A}}{0}, \ctxvar{a}{A}{\pi * \rho} \vdash
        \bang{\bang{a}} : \excl{\pi}{\excl{\rho}{A}}}
    }
    {\ctxvar{ba}{\excl{\pi * \rho}{A}}{1} \vdash
      \bm{A}{ba}{a}{\bang{\bang{a}}} : \excl{\pi}{\excl{\rho}{A}}}
  }
  {\vdash \lam{ba}{\bm{A}{ba}{a}{\bang{\bang{a}}}}
    : \fun{\excl{\pi * \rho}{A}}{\excl{\pi}{\excl{\rho}{A}}}}
\end{mathpar}

These are the counit and comultiplication required in showing that $\excl{(-)}{}$ is a
graded comonad in our category of types and functions.

\fixme{exponentials turn additives into multiplicatives}

\subsection{Admissible rules}

Recalling from \fixme{???}, $\pi \subres \rho$ says that
$\rescomment \rho$ places more relaxed restrictions than $\rescomment \pi$.
When lifted pointwise, $\resctx P \subres \resctx Q$ means that
$\resctx Q$ is a more liberal context than $\resctx
 P$, so any term well resourced in $\resctx P$ is also well
resourced in $\resctx Q$.

\begin{lemma}[Sub-resourcing]
  \[
    \inferrule*[right=subres]{
      \ctx{\Gamma}{P} \vdash M : A
      \\ \resctx P \subres \resctx Q
    }
    {
      \ctx{\Gamma}{Q} \vdash M : A
    }
  \]
\end{lemma}
\begin{proof}
  By induction on the resourcing derivation until a rule with splitting is
  encountered.
  Here, we will just consider splitting by addition, but the other cases are
  similar.
  Suppose we are given a derivation of $\ctx{\Gamma}{P} \vdash M : A$,
  from which one of the premises is
  $\resctx P_0 + \resctx P_1 \subres \resctx P$.
  Then, because $\resctx P \subres \resctx Q$, we also have
  $\resctx P_0 + \resctx P_1 \subres \resctx P$.
  Therefore, we can give a derivation for
  $\ctx{\Gamma}{Q} \vdash M : A$ which is the same as the derivation we
  were given, except with the updated splitting premise.
\end{proof}

Famously, linear logic does not allow unrestricted weakening.
Our system retains this in spirit, but contains a restricted variant.
Thinking of the $\{0,1,\omega\}$ instantiation, the following rule says that
\emph{absent} and \emph{unrestricted} variables may be weakened, but linear
variables may not be.
In the monotonicity instantiation, all annotations are above $0$, so weakening
can be applied to any variable.

\begin{lemma}[Weakening]
  We can add unmentioned free variables if those variables are annotated with a
  weakenable annotation.
  \[
    \inferrule*[right=weak]{
      \ctx{\Gamma}{P}, \ctx{\Delta}{Q} \vdash M : A
      \\ \vct 0 \subres \resctx Q
    }
    {
      \ctx{\Gamma}{P} \vdash M : A
    }
  \]
\end{lemma}

Our main syntactic lemma is substitution.
To state and prove substitution, the key insight is that semirings give rise to
an important fragment of linear algebra.
In particular, we can form vectors and matrices of semiring elements, and define
addition, scaling, and multiplication.
Addition and scaling were the two operators used in premises of typing rules.
Multiplication will be used to apply a substitution to a context.

\fixme{\ldots example of why na\"{i}ve substitution doesn't work}

Let $|-|$ denote the set of free variables of a given context.

\begin{definition}[Well resourced substitution]
  A substitution $\sigma$ from $\Gamma^{\resctx P}$ to
  $\Delta^{\resctx Q}$ is a tuple with the following data.

  \begin{itemize}
  \item a matrix $\mat \Sigma : \mathscr R^{|\resctx Q| \times |\resctx P|}$
  \item a proof that $\forall (x:A) \in \Delta.\exists M_x.~\Gamma^{\vct e_x \mat \Sigma}
    \vdash M_x : A$ %, noting that $\vct e_x \mat \Sigma$ is the $x$th column of
    %$\mat \Sigma$ as a row vector
  \item a proof that $\resctx Q \mat \Sigma \subres \resctx P$, where
    $\resctx Q$ and $\resctx P$ are viewed as row vectors
  \end{itemize}
\end{definition}

\begin{lemma}[Substitution]
  \[
    \inferrule*[right=subst]{
      \ctx{\Delta}{Q} \vdash N : A
      \\ \sigma : \ctx{\Gamma}{P} \Rightarrow \ctx{\Delta}{Q}
    }
    {
      \ctx{\Gamma}{P} \vdash N[\sigma] : A
    }
  \]
\end{lemma}
\renewcommand{\proofname}{Proof sketch}
\begin{proof}
  By induction on the resourcing derivation.
  Wherever a context is split, by any of $\vct 0 \subres \resctx R$,
  $\resctx P + \resctx Q \subres \resctx R$, or
  $\rho * \resctx P \subres \resctx R$, the linearity of vector-matrix
  multiplication means that $\mat \Sigma$ can stay the same.
  When going under a binder, the new substitution matrix will be constructed
  from the given $\mat \Sigma$ as the following.
  \newcommand*{\mathhuge}[1]{\mathlarger{\mathlarger{\mathlarger{\mathlarger{#1}}}}}
  \[
    \operatorname{extend}~\mat \Sigma \coloneqq
    %\left( \begin{array}{cccc}
    %  & & & 0 \\
    %  & \mathhuge{\mat \Sigma} & & \vdots \\
    %  & & & 0 \\
    %  0 & \cdots & 0 & 1
    %\end{array} \right)
    \begin{pmatrix}
      \mat \Sigma_{1,1} & \cdots & \mat \Sigma_{1,n} & 0 \\
      \vdots & \ddots & \vdots & \vdots \\
      \mat \Sigma_{m,1} & \cdots & \mat \Sigma_{m,n} & 0 \\
      0 & \cdots & 0 & 1
    \end{pmatrix}
    %\begin{pmatrix}
    %  \mathhuge{\mat \Sigma} & \begin{array}{c} 0 \\ \vdots \\ 0 \end{array} \\
    %  \begin{array}{ccc} 0 & \cdots & 0 \end{array} & 1
    %\end{pmatrix}
    %\begin{pmatrix}
    %  \multicolumn{3}{c}{\multirow{3}{*}{A}} & 0 \\
    %  \multicolumn{3}{c}{} & \vdots \\
    %  \multicolumn{3}{c}{} & 0 \\
    %  0 & \cdots & 0 & 1
    %\end{pmatrix}
  \]
  The new column says that to substitute the new variable by itself once, we
  need $1$ use of it, and $0$ use of any other variable.
  The new row says that the new variable will \emph{only} be used in this
  substitution by itself, and nowhere else.
\end{proof}